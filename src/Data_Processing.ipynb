{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2b759bea-375b-4d91-a3b7-9c4ad365df3c",
   "metadata": {},
   "source": [
    "# Data Processing: Mock Data\n",
    "\n",
    "We will use this notebook for modifying the data we are inputing into our model for training. We strongly recommend creating a **virtual environment** before running the following code. Don't forget to install TensorFlow dependencies into your environment."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be8d2e04-9be0-4c99-9437-dbaba7bfdce6",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Imports\n",
    "\n",
    "Next, let's invoke the necessary packages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "47306f4c-0be3-4619-9575-d4e0296e8397",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pprint\n",
    "\n",
    "from typing import Dict, Text\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import tensorflow_datasets as tfds\n",
    "\n",
    "import tensorflow_recommenders as tfrs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a753549-b20f-4a02-8ea3-7be69da9698c",
   "metadata": {},
   "source": [
    "## Dataset\n",
    "\n",
    "This is included in the TensorFlow library. We intend to use the MovieLens ratings dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "75f64cf6-2216-4e03-8d1a-f19a2afd5c31",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Ratings data.\n",
    "ratings = tfds.load(\"movielens/100k-ratings\", split=\"train\")\n",
    "# Features of all the available movies.\n",
    "movies = tfds.load(\"movielens/100k-movies\", split=\"train\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6478db7d-9111-4fa7-acd5-6746f472652c",
   "metadata": {},
   "source": [
    "Let's take a look at the data structure:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "791f869d-3c6f-4d74-bdf3-9ff09175cede",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rating: \n",
      "{'bucketized_user_age': 45.0,\n",
      " 'movie_genres': array([7], dtype=int64),\n",
      " 'movie_id': b'357',\n",
      " 'movie_title': b\"One Flew Over the Cuckoo's Nest (1975)\",\n",
      " 'raw_user_age': 46.0,\n",
      " 'timestamp': 879024327,\n",
      " 'user_gender': True,\n",
      " 'user_id': b'138',\n",
      " 'user_occupation_label': 4,\n",
      " 'user_occupation_text': b'doctor',\n",
      " 'user_rating': 4.0,\n",
      " 'user_zip_code': b'53211'}\n",
      "Movie: \n",
      "{'movie_genres': array([4], dtype=int64),\n",
      " 'movie_id': b'1681',\n",
      " 'movie_title': b'You So Crazy (1994)'}\n"
     ]
    }
   ],
   "source": [
    "for x in ratings.take(1).as_numpy_iterator():\n",
    "    print(\"Rating: \")\n",
    "    pprint.pprint(x)\n",
    "\n",
    "for x in movies.take(1).as_numpy_iterator():\n",
    "    print(\"Movie: \")\n",
    "    pprint.pprint(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b92bb925-c9ab-402a-b2aa-362233733be8",
   "metadata": {},
   "source": [
    "You can modify the limits of the previous for-loops if you would like to see more examples. The next thing to do is to process the data for saving it into a CSV file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "8f919265-fed3-4fce-97bc-f63fd1b19841",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "ratings = ratings.map(lambda x: {\n",
    "    \"media_id\": x[\"movie_id\"],\n",
    "    \"media_title\": x[\"movie_title\"],\n",
    "    \"user_id\": x[\"user_id\"],\n",
    "    \"user_rating\": x[\"user_rating\"],\n",
    "})\n",
    "\n",
    "media_items = movies.map(lambda x: {\n",
    "    \"media_id\": x[\"movie_id\"],\n",
    "    \"media_title\": x[\"movie_title\"],\n",
    "})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9f44a0f-2491-4a9a-9c68-d6213ecbb146",
   "metadata": {},
   "source": [
    "Now that we have some raw data, we will put it in separate files for further processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "4ab56580-605d-4ed6-ae0f-3a84c7f8900b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "\n",
    "with open('../RawData/raw_ratings.csv', mode='w', newline='') as csv_file:\n",
    "    csv_writer = csv.writer(csv_file, delimiter=',', quotechar='\"', quoting=csv.QUOTE_MINIMAL)\n",
    "\n",
    "    for rating in ratings.as_numpy_iterator():\n",
    "        csv_writer.writerow([rating[\"media_id\"], rating[\"media_title\"], rating[\"user_id\"], rating[\"user_rating\"]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "993ea98d-d082-4337-8212-154517829b19",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../RawData/raw_media_items.csv', mode='w', newline='') as csv_file:\n",
    "    csv_writer = csv.writer(csv_file, delimiter=',', quotechar='\"', quoting=csv.QUOTE_MINIMAL)\n",
    "\n",
    "    for item in media_items.as_numpy_iterator():\n",
    "        csv_writer.writerow([item[\"media_id\"], item[\"media_title\"]])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ac0c15d-b4e2-492a-a91e-f21d10562b0c",
   "metadata": {},
   "source": [
    "Now we are going to import some Anime data from this wonderful [GitHub repository](https://github.com/manami-project/anime-offline-database). The objective is to get an array of anime titles and years so we can use for further processing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "6b777df6-9213-477c-a6b7-3712462b4961",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "54425aac-a53a-4817-ae19-c2b2ac4fb6fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"../RawData/anime-offline-database.json\", encoding='utf-8') as data_file:\n",
    "    data = json.load(data_file)\n",
    "    \n",
    "def reduce(item):\n",
    "    return {\n",
    "        \"media_title\": item[\"title\"].encode('utf-8'),\n",
    "        \"media_year\": str(item[\"animeSeason\"][\"year\"]).encode('utf-8'),\n",
    "    }\n",
    "\n",
    "animes = list(map(reduce, data[\"data\"]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "999268da-141f-4757-ab38-f017e147843f",
   "metadata": {},
   "source": [
    "We will shuffle the data a little bit before we put it into a CSV file. We will also perform some adjustments for processing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "5a80bcee-5416-45e3-b6c1-298693026f34",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.shuffle(animes)\n",
    "\n",
    "with open('../RawData/raw_animes.csv', mode='w', newline='') as csv_file:\n",
    "    csv_writer = csv.writer(csv_file, delimiter=',', quotechar='\"', quoting=csv.QUOTE_MINIMAL)\n",
    "\n",
    "    for anime in animes:\n",
    "        csv_writer.writerow([anime[\"media_title\"], anime[\"media_year\"]])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48b8627d-0214-4207-87d3-ead80dde25b4",
   "metadata": {},
   "source": [
    "Let's take a look at our data and at the same time do some cleanup."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "e67b707e-ca89-40a0-bdfe-7895e8e3e60d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['357', \"One Flew Over the Cuckoo's Nest\", '138', '4.0'],\n",
       " ['709', 'Strictly Ballroom', '92', '2.0'],\n",
       " ['412', 'Very Brady Sequel, A', '301', '4.0'],\n",
       " ['56', 'Pulp Fiction', '60', '4.0'],\n",
       " ['895', 'Scream 2', '197', '3.0'],\n",
       " ['325', 'Crash', '601', '4.0'],\n",
       " ['95', 'Aladdin', '710', '3.0'],\n",
       " ['92', 'True Romance', '833', '2.0'],\n",
       " ['425', 'Bob Roberts', '916', '5.0'],\n",
       " ['271', 'Starship Troopers', '940', '2.0'],\n",
       " ['355', 'Sphere', '611', '1.0'],\n",
       " ['712', 'Tin Men', '707', '3.0'],\n",
       " ['825', 'Arrival, The', '699', '3.0'],\n",
       " ['240', 'Beavis and Butt-head Do America', '16', '4.0'],\n",
       " ['1150', 'Last Dance', '314', '4.0'],\n",
       " ['684', 'In the Line of Fire', '217', '5.0'],\n",
       " ['124', 'Lone Star', '276', '5.0'],\n",
       " ['294', 'Liar Liar', '510', '3.0'],\n",
       " ['265', 'Hunt for Red October, The', '757', '3.0'],\n",
       " ['465', 'Jungle Book, The', '881', '3.0']]"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open('../RawData/raw_ratings.csv') as csv_file:\n",
    "    csv_reader = csv.reader(csv_file, delimiter=',')\n",
    "    ratings_array = []\n",
    "    for row in csv_reader:\n",
    "        media_id = row[0][2:-1]\n",
    "        media_title = row[1][2:-8]\n",
    "        user_id = row[2][2:-1]\n",
    "        user_rating = row[3]\n",
    "        ratings_array.append([media_id, media_title, user_id, user_rating])\n",
    "        \n",
    "ratings_array[:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "4abff8b3-6f9f-49bf-807b-ec5e35692530",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1682"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open('../RawData/raw_media_items.csv') as csv_file:\n",
    "    csv_reader = csv.reader(csv_file, delimiter=',')\n",
    "    media_items_array = []\n",
    "    for row in csv_reader:\n",
    "        media_id = row[0][2:-1]\n",
    "        media_title = row[1][2:-8]\n",
    "        media_items_array.append([media_id, media_title])\n",
    "        \n",
    "media_items_array[:20]\n",
    "len(media_items_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "247e1a24-5b8e-4f67-a902-315a547ca189",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['Sentai Hero Sukiyaki Force: Gunma no Heiwa o Negau Season e, Mata?',\n",
       "  '2018'],\n",
       " ['Guobao Te Gong 2nd Season', '2012'],\n",
       " ['Saiunkoku Monogatari Recaps', '2007'],\n",
       " ['Lupin the IIIrd: Chikemuri no Ishikawa Goemon', '2017'],\n",
       " ['Mofumofuiction', '2018'],\n",
       " ['Kurage-P: Check Check Check One Two!', '2016'],\n",
       " ['Larva 3rd Season', '2014'],\n",
       " ['Cardfight!! Vanguard G: Stride Gate-hen', '2016'],\n",
       " ['BanG Dream! Film Live 2nd Stage', '2021'],\n",
       " ['Petit Manga', '2009'],\n",
       " ['Wakakusa Monogatari: Nan to Jo-sensei', '1993'],\n",
       " ['Wo Qi Ku Liao Baiwan Xiulian Zhe', '2021'],\n",
       " ['Artiswitch', '2021'],\n",
       " ['Jishin da!! Mii-chan no Bousai Kunren', '2006'],\n",
       " ['Tiger Mask Pilot Film', '1969'],\n",
       " ['Yowamushi Pedal: New Generation', '2017'],\n",
       " ['Mikito-P: Endroll ni Boku no Namae wo Irenaide', '2014'],\n",
       " ['Joshi Ochi!!: 2-kai kara Ero Musume ga Futte kite, Ore no Areni!?', '2018'],\n",
       " ['Kagachi-sama Onagusame Tatematsurimasu: Netorare Mura Inya Hanashi The Animation',\n",
       "  '2013'],\n",
       " ['Koneko no Chi: Ponponra Daibouken', '2016']]"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open('../RawData/raw_animes.csv') as csv_file:\n",
    "    csv_reader = csv.reader(csv_file, delimiter=',')\n",
    "    animes_array = []\n",
    "    for row in csv_reader:\n",
    "        media_title = row[0][2:-1]\n",
    "        media_year = row[1][2:-1]\n",
    "        animes_array.append([media_title, media_year])\n",
    "        \n",
    "animes_array[:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f9f0a91-c8ea-47a3-82b6-9e5fc14eeab5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
